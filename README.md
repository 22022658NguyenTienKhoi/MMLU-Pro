# MMLU-Pro

This repository contains the evaluation code for MMLU-Pro, which includes methods for utilizing local computing resources for inference and for invoking APIs.

## Usage

### Local Inference

To run local inference, follow these steps:

```bash
cd scripts/example/
sh eval_llama_2_7b.sh
```

Using the API
To use the API for inference, follow these steps:

```bash
cd scripts/example/
sh eval_gpt_4.sh
```

